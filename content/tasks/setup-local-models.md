---
title: "Start LM Studio with a small local model"
status: todo
priority: next
assignee: tom
created: '2026-02-12'
notes: "Free, unlimited AI workers for routine tasks"
---

## Why
Small local models can handle proofreading, JSON validation, template filling, and other routine tasks — for free. Saves Opus tokens for strategic work.

## What To Do
1. Open LM Studio (already installed)
2. Download **Phi-4-mini (Q4)** — ~2.5GB, runs well on M1 8GB
3. Start the local server (it serves on `localhost:1234`)
4. That's it — I call it via HTTP

## What I'll Do With It
- Copy proofreading
- Config/JSON validation
- Simple data extraction
- Template variation generation
- Code linting checks
